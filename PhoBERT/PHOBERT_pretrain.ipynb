{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import và cài đặt"
      ],
      "metadata": {
        "id": "mpod1u0a7Tsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7tw5qzU-Uh38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc32c0fa-666a-4c64-a87c-0f6751db77ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install vncorenlp -q\n",
        "!pip install pyyaml -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MeWgCnsj7bQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7ac2f1-cce4-4a7b-e188-fe4dd99777eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from argparse import Namespace\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "klO0ZrqYBo0U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_config(config_path: str) -> Namespace:\n",
        "    with open(config_path, 'r') as f:\n",
        "        cfg_dict = yaml.safe_load(f)\n",
        "\n",
        "    def dict_to_namespace(d):\n",
        "        if isinstance(d, dict):\n",
        "            return Namespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
        "        elif isinstance(d, list):\n",
        "            return [dict_to_namespace(x) for x in d]\n",
        "        else:\n",
        "            return d\n",
        "\n",
        "    return dict_to_namespace(cfg_dict)\n",
        "\n"
      ],
      "metadata": {
        "id": "TGTYKgakCTSV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data"
      ],
      "metadata": {
        "id": "5B7OX6tM8B8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PhoBERTDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "-_6coB1G8BJ1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. PhoBERT"
      ],
      "metadata": {
        "id": "qGyTdQ3S-IKa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ncGVmD7VmdCQ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class PhoBERTClassifier(nn.Module):\n",
        "    def __init__(self, model_name=\"vinai/phobert-base\", num_labels=2, dropout_rate=0.3, freeze_phobert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.phobert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        if freeze_phobert:\n",
        "            for param in self.phobert.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(\"=> PhoBERT đã được freeze. Chỉ huấn luyện classifier.\")\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.phobert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0]  # Lấy token [CLS]\n",
        "        return self.classifier(self.dropout(cls_output))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Trainer"
      ],
      "metadata": {
        "id": "hS2GFDtA-QOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5wJ3s_P6H8vW"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, config):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    logs = []\n",
        "\n",
        "    for epoch in range(config.training.epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "        val_acc, val_f1, val_prec, val_rec, val_auc = evaluate_model(model, val_loader)\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        logs.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'time': round(elapsed_time, 2),\n",
        "            'train_acc': round(train_acc, 4),\n",
        "            'val_acc': round(val_acc, 4),\n",
        "            'f1': round(val_f1, 4),\n",
        "            'precision': round(val_prec, 4),\n",
        "            'recall': round(val_rec, 4),\n",
        "            'auc': round(val_auc, 4),\n",
        "        })\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] Time: {elapsed_time:.2f}s - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f} - F1: {val_f1:.4f} - Precision: {val_prec:.4f} - Recall: {val_rec:.4f} - AUC: {val_auc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), config.training.checkpoint_path)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config.training.early_stopping.patience:\n",
        "                print(\"=> Early stopping.\")\n",
        "                break\n",
        "\n",
        "        # Save logs after each epoch\n",
        "        pd.DataFrame(logs).to_csv(config.training.log_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluator"
      ],
      "metadata": {
        "id": "TGkt7ZuW-iNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eU548TQzI28X"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, classification_report\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    print(classification_report(all_labels, all_preds, digits=4, zero_division=0))\n",
        "    return acc, f1, prec, rec, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Chạy"
      ],
      "metadata": {
        "id": "QQsuIDAXC2Q4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73lM2My9KzRN",
        "outputId": "4dd489f2-6aaf-4d46-fa88-86afc371dc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/config_phobert_train1.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/config_phobert_pretrain1.yaml\"\n",
        "\n",
        "mode: pretrain #train\n",
        "seed: 42\n",
        "\n",
        "paths:\n",
        "  train: \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/reintel_dataset/train.csv\"\n",
        "  test: \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/reintel_dataset/test.csv\"\n",
        "  val: \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/reintel_dataset/val.csv\"\n",
        "  #train: \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/reintel_dataset/warmup.csv\"\n",
        "\n",
        "preprocessing:\n",
        "  phobert:\n",
        "    max_sequence_length: 256\n",
        "\n",
        "models:\n",
        "  phobert:\n",
        "    model_name: \"vinai/phobert-base\"\n",
        "    hidden_size: 768\n",
        "    dropout_rate: 0.3\n",
        "    num_labels: 2\n",
        "\n",
        "training:\n",
        "  batch_size: 32\n",
        "  epochs: 10\n",
        "  checkpoint_path: \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/PhoBert/checkpoints/phobert_pretrain1.pt\"\n",
        "  log_path: \"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/PhoBert/logs/phobert_training_pretrain1.csv\"\n",
        "  early_stopping:\n",
        "    patience: 3\n",
        "  device: auto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "waEjeeIqVh47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c56708-6896-48df-e48b-9566a57a511c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> PhoBERT đã được freeze. Chỉ huấn luyện classifier.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 1] Training: 100%|██████████| 274/274 [02:10<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8313    1.0000    0.9079       404\n",
            "           1     0.0000    0.0000    0.0000        82\n",
            "\n",
            "    accuracy                         0.8313       486\n",
            "   macro avg     0.4156    0.5000    0.4539       486\n",
            "weighted avg     0.6910    0.8313    0.7547       486\n",
            "\n",
            "[Epoch 1] Time: 137.04s - Train Acc: 0.7426 - Val Acc: 0.8313 - F1: 0.4539 - Precision: 0.4156 - Recall: 0.5000 - AUC: 0.4505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 2] Training: 100%|██████████| 274/274 [02:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8313    1.0000    0.9079       404\n",
            "           1     0.0000    0.0000    0.0000        82\n",
            "\n",
            "    accuracy                         0.8313       486\n",
            "   macro avg     0.4156    0.5000    0.4539       486\n",
            "weighted avg     0.6910    0.8313    0.7547       486\n",
            "\n",
            "[Epoch 2] Time: 131.60s - Train Acc: 0.8307 - Val Acc: 0.8313 - F1: 0.4539 - Precision: 0.4156 - Recall: 0.5000 - AUC: 0.5936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 3] Training: 100%|██████████| 274/274 [02:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8313    1.0000    0.9079       404\n",
            "           1     0.0000    0.0000    0.0000        82\n",
            "\n",
            "    accuracy                         0.8313       486\n",
            "   macro avg     0.4156    0.5000    0.4539       486\n",
            "weighted avg     0.6910    0.8313    0.7547       486\n",
            "\n",
            "[Epoch 3] Time: 129.70s - Train Acc: 0.8317 - Val Acc: 0.8313 - F1: 0.4539 - Precision: 0.4156 - Recall: 0.5000 - AUC: 0.7020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 4] Training: 100%|██████████| 274/274 [02:03<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8313    1.0000    0.9079       404\n",
            "           1     0.0000    0.0000    0.0000        82\n",
            "\n",
            "    accuracy                         0.8313       486\n",
            "   macro avg     0.4156    0.5000    0.4539       486\n",
            "weighted avg     0.6910    0.8313    0.7547       486\n",
            "\n",
            "[Epoch 4] Time: 129.54s - Train Acc: 0.8317 - Val Acc: 0.8313 - F1: 0.4539 - Precision: 0.4156 - Recall: 0.5000 - AUC: 0.7626\n",
            "=> Early stopping.\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "config = load_config(\"/content/drive/MyDrive/1.PROJECTS/[TeamPe][BIT][BGRA2025]/NLP/Code/config_phobert.yaml\")\n",
        "\n",
        "train_df = pd.read_csv(config.paths.train)\n",
        "val_df = pd.read_csv(config.paths.val)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "train_dataset = PhoBERTDataset(train_df['post_message'].tolist(), train_df['label'].tolist(), tokenizer, config.preprocessing.phobert.max_sequence_length)\n",
        "val_dataset = PhoBERTDataset(val_df['post_message'].tolist(), val_df['label'].tolist(), tokenizer, config.preprocessing.phobert.max_sequence_length)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.training.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.training.batch_size)\n",
        "\n",
        "# Train model\n",
        "model = PhoBERTClassifier(model_name=config.models.phobert.model_name, num_labels=config.models.phobert.num_labels, freeze_phobert=True)\n",
        "train_model(model, train_loader, val_loader, config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "49e55C0TKdWK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E8T7t-08Tf0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefbfd34-a959-471e-98de-bae8773eb4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8313    1.0000    0.9079       404\n",
            "           1     0.0000    0.0000    0.0000        82\n",
            "\n",
            "    accuracy                         0.8313       486\n",
            "   macro avg     0.4156    0.5000    0.4539       486\n",
            "weighted avg     0.6910    0.8313    0.7547       486\n",
            "\n",
            "\n",
            "✅ Test Accuracy: 0.8313\n",
            "✅ Test F1 (macro): 0.4539\n",
            "✅ Test Precision: 0.4156\n",
            "✅ Test Recall: 0.5000\n",
            "✅ Test AUC: 0.5215\n"
          ]
        }
      ],
      "source": [
        "# Load lại tokenizer & model\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.models.phobert.model_name)\n",
        "model = PhoBERTClassifier(\n",
        "    model_name=config.models.phobert.model_name,\n",
        "    num_labels=config.models.phobert.num_labels\n",
        ")\n",
        "\n",
        "# Load checkpoint tốt nhất\n",
        "model.load_state_dict(torch.load(config.training.checkpoint_path, map_location='cpu'))\n",
        "\n",
        "# Chuẩn bị dữ liệu test\n",
        "test_df = pd.read_csv(config.paths.test)\n",
        "test_dataset = PhoBERTDataset(\n",
        "    texts=test_df['post_message'].tolist(),\n",
        "    labels=test_df['label'].tolist(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=config.preprocessing.phobert.max_sequence_length\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.training.batch_size)\n",
        "\n",
        "# Gọi đánh giá\n",
        "acc, f1, precision, recall, auc = evaluate_model(model, test_loader)\n",
        "\n",
        "print(f\"\\n✅ Test Accuracy: {acc:.4f}\")\n",
        "print(f\"✅ Test F1 (macro): {f1:.4f}\")\n",
        "print(f\"✅ Test Precision: {precision:.4f}\")\n",
        "print(f\"✅ Test Recall: {recall:.4f}\")\n",
        "print(f\"✅ Test AUC: {auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y6OOzN_hU2bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kreHAkduGqqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TyH57zKWEuD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Khh653ZJA-H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmJzznjlXVk5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-RbcaHecj2X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}